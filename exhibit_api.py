# exhibit_api_fixed.py
import os
import cv2
import numpy as np
import chromadb
from PIL import Image
from flask import Flask, request, jsonify
import logging
import io
import requests  # æ·»åŠ requestsåº“ç”¨äºä¸‹è½½å›¾ç‰‡
import time
import uuid
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__)

print("ğŸš€ å¯åŠ¨ä¿®å¤ç‰ˆè‰ºæœ¯å±•å“è¯†åˆ«API...")

# è¿æ¥å‘é‡æ•°æ®åº“
client = chromadb.PersistentClient(path="./exhibit_vector_db")
collection = client.get_collection("art_exhibits")

print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ! åŒ…å« {collection.count()} æ¡è®°å½•")


class RobustFeatureExtractor:
    def __init__(self):
        self.orb = cv2.ORB_create(nfeatures=300)
        logger.info("ç‰¹å¾æå–å™¨åˆå§‹åŒ–å®Œæˆ")

    def extract_orb_features(self, image):
        """ä½¿ç”¨ORBæå–ç‰¹å¾ - ä¸æ„å»ºæ•°æ®åº“æ—¶ä¸€è‡´"""
        try:
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            keypoints, descriptors = self.orb.detectAndCompute(gray, None)

            if descriptors is not None and len(descriptors) > 5:
                mean_desc = descriptors.mean(axis=0)
                if len(mean_desc) > 32:
                    mean_desc = mean_desc[:32]
                elif len(mean_desc) < 32:
                    mean_desc = np.pad(mean_desc, (0, 32 - len(mean_desc)))

                norm = np.linalg.norm(mean_desc)
                return mean_desc / norm if norm > 0 else mean_desc
            return None
        except Exception as e:
            logger.warning(f"ORBç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def extract_color_features(self, image):
        """æå–é¢œè‰²ç‰¹å¾ - ä¸æ„å»ºæ•°æ®åº“æ—¶ä¸€è‡´"""
        try:
            if len(image.shape) == 3:
                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])
                hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])
                hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])

                hist = np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])
                hist = cv2.normalize(hist, hist).flatten()
                return hist
            else:
                hist = cv2.calcHist([image], [0], None, [32], [0, 256])
                hist = cv2.normalize(hist, hist).flatten()
                return hist
        except Exception as e:
            logger.warning(f"é¢œè‰²ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def extract_texture_features(self, image):
        """æå–çº¹ç†ç‰¹å¾ - ä¸æ„å»ºæ•°æ®åº“æ—¶ä¸€è‡´"""
        try:
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # è®¡ç®—LBPçº¹ç†ç‰¹å¾
            lbp = self.local_binary_pattern(gray)
            hist, _ = np.histogram(lbp.ravel(), bins=256, range=[0, 256])
            hist = hist.astype(np.float32)
            hist = cv2.normalize(hist, hist).flatten()
            return hist
        except Exception as e:
            logger.warning(f"çº¹ç†ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def local_binary_pattern(self, image, P=8, R=1):
        """è®¡ç®—å±€éƒ¨äºŒå€¼æ¨¡å¼"""
        height, width = image.shape
        lbp = np.zeros((height - 2, width - 2), dtype=np.uint8)

        for i in range(1, height - 1):
            for j in range(1, width - 1):
                center = image[i, j]
                code = 0
                code |= (image[i - 1, j - 1] > center) << 7
                code |= (image[i - 1, j] > center) << 6
                code |= (image[i - 1, j + 1] > center) << 5
                code |= (image[i, j + 1] > center) << 4
                code |= (image[i + 1, j + 1] > center) << 3
                code |= (image[i + 1, j] > center) << 2
                code |= (image[i + 1, j - 1] > center) << 1
                code |= (image[i, j - 1] > center) << 0
                lbp[i - 1, j - 1] = code
        return lbp

    def extract_features(self, image_path):
        """ç»¼åˆç‰¹å¾æå– - ä¸æ„å»ºæ•°æ®åº“æ—¶å®Œå…¨ä¸€è‡´"""
        try:
            # ä½¿ç”¨PILè¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
            pil_image = Image.open(image_path)
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')

            # è°ƒæ•´å›¾ç‰‡å¤§å°
            max_size = 800
            if max(pil_image.size) > max_size:
                ratio = max_size / max(pil_image.size)
                new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)

            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv2_image = self.pil_to_cv2(pil_image)

            features = []

            # æ–¹æ³•1: ORBç‰¹å¾
            orb_feat = self.extract_orb_features(cv2_image)
            if orb_feat is not None:
                features.extend(orb_feat)
            else:
                features.extend([0] * 32)

            # æ–¹æ³•2: é¢œè‰²ç‰¹å¾
            color_feat = self.extract_color_features(cv2_image)
            if color_feat is not None:
                features.extend(color_feat)
            else:
                features.extend([0] * 24)

            # æ–¹æ³•3: çº¹ç†ç‰¹å¾
            texture_feat = self.extract_texture_features(cv2_image)
            if texture_feat is not None:
                features.extend(texture_feat)
            else:
                features.extend([0] * 256)

            # ç¡®ä¿ç‰¹å¾å‘é‡é•¿åº¦ä¸€è‡´
            target_length = 312
            if len(features) > target_length:
                features = features[:target_length]
            elif len(features) < target_length:
                features.extend([0] * (target_length - len(features)))

            feature_vector = np.array(features, dtype=np.float32)
            norm = np.linalg.norm(feature_vector)

            if norm > 0:
                feature_vector = feature_vector / norm

            return feature_vector.tolist()

        except Exception as e:
            logger.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def pil_to_cv2(self, pil_image):
        """PILå›¾åƒè½¬OpenCVæ ¼å¼"""
        cv2_image = np.array(pil_image)
        cv2_image = cv2_image[:, :, ::-1].copy()
        return cv2_image


# å…¨å±€ç‰¹å¾æå–å™¨
feature_extractor = RobustFeatureExtractor()


def extract_query_features(image_bytes):
    """æŸ¥è¯¢ç‰¹å¾æå– - ä¸æ„å»ºæ—¶å®Œå…¨ä¸€è‡´"""
    try:
        # ä½¿ç”¨PILè¯»å–å›¾ç‰‡å­—èŠ‚
        pil_image = Image.open(io.BytesIO(image_bytes))
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')

        # è°ƒæ•´å¤§å°
        max_size = 800
        if max(pil_image.size) > max_size:
            ratio = max_size / max(pil_image.size)
            new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))
            pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)

        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ç”¨äºç‰¹å¾æå–
        temp_path = "temp_query_image.jpg"
        pil_image.save(temp_path)

        # ä½¿ç”¨ä¸æ„å»ºæ—¶å®Œå…¨ç›¸åŒçš„æ–¹æ³•
        features = feature_extractor.extract_features(temp_path)

        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.remove(temp_path)

        return features

    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç‰¹å¾æå–å¤±è´¥: {e}")
        return None


def identify_from_image_data(image_data):
    """é€šç”¨çš„è¯†åˆ«é€»è¾‘"""
    # æå–ç‰¹å¾ï¼ˆä½¿ç”¨ä¸æ„å»ºæ—¶å®Œå…¨ç›¸åŒçš„æ–¹æ³•ï¼‰
    query_vector = extract_query_features(image_data)

    if query_vector is None:
        return {"status": "error", "message": "ç‰¹å¾æå–å¤±è´¥"}

    # æœç´¢ç›¸ä¼¼å±•å“
    results = collection.query(
        query_embeddings=[query_vector],
        n_results=5,
        include=["metadatas", "distances"]
    )

    if results and results['metadatas']:
        metadatas = results['metadatas'][0]
        distances = results['distances'][0]

        # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
        similarities = [1 - distance for distance in distances]

        # æ‰¾åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„ç»“æœ
        best_match_idx = np.argmax(similarities)
        best_similarity = similarities[best_match_idx]
        best_metadata = metadatas[best_match_idx]

        # é™ä½é˜ˆå€¼åˆ°0.3
        if best_similarity >= 0.3:
            return {
                "status": "success",
                "exhibit_id": best_metadata["exhibit_id"],
                "confidence": round(best_similarity, 4),
                "category": best_metadata["category"],
                "message": f"è¯†åˆ«æˆåŠŸ: {best_metadata['exhibit_id']}",
                "all_matches": [
                    {
                        "exhibit_id": meta["exhibit_id"],
                        "confidence": round(sim, 4)
                    }
                    for meta, sim in zip(metadatas, similarities)
                ]
            }

    return {
        "status": "not_found",
        "exhibit_id": None,
        "confidence": 0.0,
        "message": "æœªæ‰¾åˆ°åŒ¹é…çš„å±•å“"
    }


@app.route('/identify', methods=['POST'])
def identify_exhibit():
    """è¯†åˆ«å±•å“ - æ–‡ä»¶ä¸Šä¼ æ–¹å¼"""
    try:
        logger.info("æ”¶åˆ°æ–‡ä»¶è¯†åˆ«è¯·æ±‚")

        if 'file' not in request.files:
            return jsonify({"status": "error", "message": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({"status": "error", "message": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400

        # è¯»å–å›¾ç‰‡æ•°æ®
        image_data = file.read()
        if len(image_data) == 0:
            return jsonify({"status": "error", "message": "ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©º"}), 400

        # ä½¿ç”¨é€šç”¨è¯†åˆ«é€»è¾‘
        result = identify_from_image_data(image_data)
        return jsonify(result)

    except Exception as e:
        logger.error(f"æ–‡ä»¶è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
        return jsonify({"status": "error", "message": f"è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {str(e)}"}), 500


# === ä¿®æ”¹ identify_by_url å‡½æ•° ===
@app.route('/identify_by_url', methods=['POST'])
def identify_by_url():
    try:
        data = request.get_json()
        image_url = data.get('image_url')

        # ç”Ÿæˆå”¯ä¸€è¯·æ±‚æ ‡è¯†
        request_id = str(uuid.uuid4())[:8]
        timestamp = datetime.now().strftime("%H:%M:%S")

        logger.info(f"ğŸ†• è¯·æ±‚ {request_id} | æ—¶é—´ {timestamp} | å¼€å§‹è¯†åˆ«: {image_url[:50]}...")

        # ä¸‹è½½å›¾ç‰‡
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(image_url, headers=headers, timeout=30)

        if response.status_code != 200:
            logger.error(f"âŒ è¯·æ±‚ {request_id} | ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
            return jsonify({
                "status": "error",
                "message": f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {response.status_code}",
                "request_id": request_id
            }), 400

        # ç›´æ¥ä½¿ç”¨ identify_from_image_data å‡½æ•°ï¼ˆä½ å®é™…ä½¿ç”¨çš„å‡½æ•°ï¼‰
        result = identify_from_image_data(response.content)

        # å¦‚æœä¸Šé¢æŠ¥é”™ï¼Œå°è¯•ä½¿ç”¨ extract_query_features
        # result = process_image_recognition(response.content, request_id)

        # å¢å¼ºè¿”å›ç»“æœ
        if result['status'] == 'success':
            result.update({
                'request_id': request_id,
                'timestamp': timestamp,
                'is_new_request': True,
                'cache_used': False,
                'message': f"ğŸ†• è¯†åˆ«æˆåŠŸ: {result['exhibit_id']} (è¯·æ±‚ID: {request_id})"
            })
            logger.info(f"âœ… è¯·æ±‚ {request_id} | è¯†åˆ«æˆåŠŸ: {result['exhibit_id']}")
        else:
            result.update({
                'request_id': request_id,
                'timestamp': timestamp,
                'is_new_request': True
            })
            logger.info(f"âŒ è¯·æ±‚ {request_id} | è¯†åˆ«å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

        return jsonify(result)

    except Exception as e:
        logger.error(f"ğŸ’¥ è¯·æ±‚å¤„ç†å¼‚å¸¸: {e}")
        return jsonify({
            "status": "error",
            "message": f"è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {str(e)}",
            "request_id": request_id if 'request_id' in locals() else 'unknown'
        }), 500


# === æ–°å¢ï¼šç»Ÿä¸€çš„å›¾ç‰‡è¯†åˆ«å¤„ç†å‡½æ•° ===
def process_image_recognition(image_data, request_id):
    """ç»Ÿä¸€çš„å›¾ç‰‡è¯†åˆ«å¤„ç†"""
    try:
        # æå–ç‰¹å¾
        query_vector = extract_query_features(image_data)

        if query_vector is None:
            return {"status": "error", "message": "ç‰¹å¾æå–å¤±è´¥"}

        # æœç´¢ç›¸ä¼¼å±•å“
        results = collection.query(
            query_embeddings=[query_vector],
            n_results=5,
            include=["metadatas", "distances"]
        )

        if results and results['metadatas']:
            metadatas = results['metadatas'][0]
            distances = results['distances'][0]

            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
            similarities = [1 - distance for distance in distances]

            # æ‰¾åˆ°ç›¸ä¼¼åº¦æœ€é«˜çš„ç»“æœ
            best_match_idx = np.argmax(similarities)
            best_similarity = similarities[best_match_idx]
            best_metadata = metadatas[best_match_idx]

            # é™ä½é˜ˆå€¼åˆ°0.3
            if best_similarity >= 0.3:
                return {
                    "status": "success",
                    "exhibit_id": best_metadata["exhibit_id"],
                    "confidence": round(best_similarity, 4),
                    "category": best_metadata.get("category", ""),
                    "similarities": similarities,  # è¿”å›æ‰€æœ‰ç›¸ä¼¼åº¦ç”¨äºè°ƒè¯•
                    "all_matches": [
                        {
                            "exhibit_id": meta["exhibit_id"],
                            "confidence": round(sim, 4)
                        }
                        for meta, sim in zip(metadatas, similarities)
                    ]
                }

        return {
            "status": "not_found",
            "exhibit_id": None,
            "confidence": 0.0,
            "message": "æœªæ‰¾åˆ°åŒ¹é…çš„å±•å“"
        }

    except Exception as e:
        logger.error(f"ç‰¹å¾è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
        return {"status": "error", "message": f"è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {str(e)}"}


@app.route('/debug_clear_cache', methods=['POST'])
def debug_clear_cache():
    """æ¸…ç†å¯èƒ½çš„ç¼“å­˜"""
    try:
        # å¦‚æœæœ‰ä»»ä½•å…¨å±€ç¼“å­˜å˜é‡ï¼Œåœ¨è¿™é‡Œæ¸…ç†
        global feature_cache
        if 'feature_cache' in globals():
            feature_cache.clear()

        # æ¸…ç†å¯èƒ½çš„å‡½æ•°ç¼“å­˜
        import functools
        if hasattr(extract_query_features, 'cache'):
            extract_query_features.cache_clear()

        return jsonify({
            "status": "success",
            "message": "ç¼“å­˜å·²æ¸…ç†",
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}"
        })


@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "service": "exhibit-recognition",
        "database_records": collection.count()
    })


@app.route('/exhibits', methods=['GET'])
def list_exhibits():
    try:
        results = collection.get(limit=1000)
        exhibits = {}
        for metadata in results['metadatas']:
            exhibit_id = metadata['exhibit_id']
            if exhibit_id not in exhibits:
                exhibits[exhibit_id] = {
                    "category": metadata['category'],
                    "image_count": 0
                }
            exhibits[exhibit_id]['image_count'] += 1

        return jsonify({
            "status": "success",
            "total_exhibits": len(exhibits),
            "exhibits": exhibits
        })
    except Exception as e:
        return jsonify({"status": "error", "message": f"è·å–å±•å“åˆ—è¡¨å¤±è´¥: {str(e)}"}), 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=False)