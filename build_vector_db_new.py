# build_vector_db_fixed.py
import os
import cv2
import numpy as np
import chromadb
from PIL import Image
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RobustFeatureExtractor:
    def __init__(self):
        """ä½¿ç”¨å¤šç§ç‰¹å¾æå–æ–¹æ³•ç¡®ä¿ç¨³å®šæ€§"""
        # æ–¹æ³•1: ORBç‰¹å¾
        self.orb = cv2.ORB_create(nfeatures=300)
        logger.info("ç¦»çº¿ç‰¹å¾æå–å™¨åˆå§‹åŒ–å®Œæˆ")

    def pil_to_cv2(self, pil_image):
        """å°†PILå›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼"""
        # PILæ˜¯RGB, OpenCVæ˜¯BGR
        cv2_image = np.array(pil_image)
        cv2_image = cv2_image[:, :, ::-1].copy()  # RGB to BGR
        return cv2_image

    def extract_orb_features(self, image):
        """ä½¿ç”¨ORBæå–ç‰¹å¾"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            keypoints, descriptors = self.orb.detectAndCompute(gray, None)

            if descriptors is not None and len(descriptors) > 5:
                # ä½¿ç”¨æè¿°ç¬¦çš„å‡å€¼ä½œä¸ºç‰¹å¾å‘é‡
                mean_desc = descriptors.mean(axis=0)

                # ç¡®ä¿å‘é‡é•¿åº¦ä¸º32ï¼ˆORBé»˜è®¤ï¼‰
                if len(mean_desc) > 32:
                    mean_desc = mean_desc[:32]
                elif len(mean_desc) < 32:
                    mean_desc = np.pad(mean_desc, (0, 32 - len(mean_desc)))

                # å½’ä¸€åŒ–
                norm = np.linalg.norm(mean_desc)
                return mean_desc / norm if norm > 0 else mean_desc
            return None
        except Exception as e:
            logger.warning(f"ORBç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def extract_color_features(self, image):
        """ä½¿ç”¨é¢œè‰²ç›´æ–¹å›¾ä½œä¸ºç‰¹å¾"""
        try:
            if len(image.shape) == 3:
                # è®¡ç®—HSVé¢œè‰²ç›´æ–¹å›¾
                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])
                hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])
                hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])

                # åˆå¹¶å¹¶å½’ä¸€åŒ–
                hist = np.concatenate([hist_h.flatten(), hist_s.flatten(), hist_v.flatten()])
                hist = cv2.normalize(hist, hist).flatten()
                return hist
            else:
                # ç°åº¦å›¾ï¼Œåªè®¡ç®—äº®åº¦ç›´æ–¹å›¾
                hist = cv2.calcHist([image], [0], None, [32], [0, 256])
                hist = cv2.normalize(hist, hist).flatten()
                return hist
        except Exception as e:
            logger.warning(f"é¢œè‰²ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def extract_texture_features(self, image):
        """ä½¿ç”¨çº¹ç†ç‰¹å¾"""
        try:
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # è®¡ç®—LBPçº¹ç†ç‰¹å¾
            lbp = self.local_binary_pattern(gray)
            hist, _ = np.histogram(lbp.ravel(), bins=256, range=[0, 256])
            hist = hist.astype(np.float32)
            hist = cv2.normalize(hist, hist).flatten()
            return hist
        except Exception as e:
            logger.warning(f"çº¹ç†ç‰¹å¾æå–å¤±è´¥: {e}")
            return None

    def local_binary_pattern(self, image, P=8, R=1):
        """è®¡ç®—å±€éƒ¨äºŒå€¼æ¨¡å¼"""
        height, width = image.shape
        lbp = np.zeros((height - 2, width - 2), dtype=np.uint8)

        for i in range(1, height - 1):
            for j in range(1, width - 1):
                center = image[i, j]
                code = 0
                code |= (image[i - 1, j - 1] > center) << 7
                code |= (image[i - 1, j] > center) << 6
                code |= (image[i - 1, j + 1] > center) << 5
                code |= (image[i, j + 1] > center) << 4
                code |= (image[i + 1, j + 1] > center) << 3
                code |= (image[i + 1, j] > center) << 2
                code |= (image[i + 1, j - 1] > center) << 1
                code |= (image[i, j - 1] > center) << 0
                lbp[i - 1, j - 1] = code
        return lbp

    def extract_features(self, image_path):
        """ç»¼åˆç‰¹å¾æå– - ä½¿ç”¨PILè¯»å–å›¾ç‰‡é¿å…ä¸­æ–‡è·¯å¾„é—®é¢˜"""
        try:
            # ä½¿ç”¨PILè¯»å–å›¾ç‰‡ï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰
            pil_image = Image.open(image_path)

            # è½¬æ¢ä¸ºRGBï¼ˆç¡®ä¿3é€šé“ï¼‰
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')

            # è°ƒæ•´å›¾ç‰‡å¤§å°ä»¥åŠ å¿«å¤„ç†é€Ÿåº¦
            max_size = 800
            if max(pil_image.size) > max_size:
                ratio = max_size / max(pil_image.size)
                new_size = (int(pil_image.size[0] * ratio), int(pil_image.size[1] * ratio))
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)

            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv2_image = self.pil_to_cv2(pil_image)

            features = []

            # æ–¹æ³•1: ORBç‰¹å¾
            orb_feat = self.extract_orb_features(cv2_image)
            if orb_feat is not None:
                features.extend(orb_feat)
            else:
                # å¦‚æœORBå¤±è´¥ï¼Œç”¨é›¶å¡«å……
                features.extend([0] * 32)

            # æ–¹æ³•2: é¢œè‰²ç‰¹å¾
            color_feat = self.extract_color_features(cv2_image)
            if color_feat is not None:
                features.extend(color_feat)
            else:
                features.extend([0] * 24)  # 8+8+8=24

            # æ–¹æ³•3: çº¹ç†ç‰¹å¾
            texture_feat = self.extract_texture_features(cv2_image)
            if texture_feat is not None:
                features.extend(texture_feat)
            else:
                features.extend([0] * 256)

            # ç¡®ä¿ç‰¹å¾å‘é‡é•¿åº¦ä¸€è‡´
            target_length = 312  # 32 + 24 + 256
            if len(features) > target_length:
                features = features[:target_length]
            elif len(features) < target_length:
                features.extend([0] * (target_length - len(features)))

            feature_vector = np.array(features, dtype=np.float32)
            norm = np.linalg.norm(feature_vector)

            if norm > 0:
                feature_vector = feature_vector / norm

            logger.info(f"âœ… æˆåŠŸæå–ç‰¹å¾: {os.path.basename(image_path)}")
            return feature_vector.tolist()

        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾æå–å¤±è´¥ {os.path.basename(image_path)}: {e}")
            return None


class ExhibitVectorizer:
    def __init__(self):
        self.feature_extractor = RobustFeatureExtractor()
        self.client = chromadb.PersistentClient(path="./exhibit_vector_db")
        logger.info("å±•å“å‘é‡åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")

    def create_collection(self, collection_name="art_exhibits"):
        """åˆ›å»ºå‘é‡æ•°æ®åº“é›†åˆ"""
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        logger.info(f"å‘é‡æ•°æ®åº“é›†åˆ '{collection_name}' åˆ›å»ºæˆåŠŸ")

    def scan_dataset(self, dataset_path):
        """æ‰«ææ•°æ®é›†å¹¶æ•´ç†å±•å“ç»“æ„"""
        exhibits = {}

        logger.info(f"å¼€å§‹æ‰«ææ•°æ®é›†: {dataset_path}")

        if not os.path.exists(dataset_path):
            logger.error(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
            return exhibits

        # éå†åˆ†ç±»æ–‡ä»¶å¤¹
        for category in os.listdir(dataset_path):
            category_path = os.path.join(dataset_path, category)
            if not os.path.isdir(category_path):
                continue

            logger.info(f"æ‰«æåˆ†ç±»: {category}")

            # éå†åˆ†ç±»ä¸‹çš„æ‰€æœ‰é¡¹ç›®
            for item in os.listdir(category_path):
                item_path = os.path.join(category_path, item)

                if os.path.isfile(item_path) and item.lower().endswith(('.jpg', '.jpeg', '.png')):
                    # å•ä¸ªå›¾ç‰‡æ–‡ä»¶
                    exhibit_id = f"{category}_{os.path.splitext(item)[0]}"
                    if exhibit_id not in exhibits:
                        exhibits[exhibit_id] = []
                    exhibits[exhibit_id].append(item_path)

                elif os.path.isdir(item_path):
                    # å›¾ç‰‡æ–‡ä»¶å¤¹
                    exhibit_id = f"{category}_{item}"
                    image_list = []

                    for img_file in os.listdir(item_path):
                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            img_path = os.path.join(item_path, img_file)
                            image_list.append(img_path)

                    if image_list:
                        exhibits[exhibit_id] = image_list

        total_images = sum(len(images) for images in exhibits.values())
        logger.info(f"æ•°æ®é›†æ‰«æå®Œæˆ: å…± {len(exhibits)} ä¸ªå±•å“, {total_images} å¼ å›¾ç‰‡")

        return exhibits

    def build_vector_database(self, dataset_path):
        """æ„å»ºå‘é‡æ•°æ®åº“"""
        # æ‰«ææ•°æ®é›†
        exhibits = self.scan_dataset(dataset_path)

        if not exhibits:
            logger.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å±•å“å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„")
            return False

        # å¤„ç†å›¾ç‰‡å¹¶å­˜å…¥å‘é‡æ•°æ®åº“
        all_embeddings = []
        all_metadatas = []
        all_ids = []

        total_images = sum(len(images) for images in exhibits.values())
        processed_count = 0
        success_count = 0

        logger.info("å¼€å§‹æå–ç‰¹å¾å¹¶æ„å»ºå‘é‡æ•°æ®åº“...")

        for exhibit_id, image_list in exhibits.items():
            logger.info(f"å¤„ç†å±•å“: {exhibit_id} ({len(image_list)} å¼ å›¾ç‰‡)")

            for i, image_path in enumerate(image_list):
                processed_count += 1

                print(f"è¿›åº¦: {processed_count}/{total_images} - {os.path.basename(image_path)}")

                # æå–ç‰¹å¾
                vector = self.feature_extractor.extract_features(image_path)
                if vector is not None:
                    all_embeddings.append(vector)
                    all_metadatas.append({
                        "exhibit_id": exhibit_id,
                        "image_path": image_path,
                        "category": exhibit_id.split('_')[0],
                        "image_name": os.path.basename(image_path),
                        "angle": f"angle_{i}",
                        "type": "exhibit_reference"
                    })
                    all_ids.append(f"{exhibit_id}_{i}")
                    success_count += 1

        # ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
        if all_embeddings:
            self.collection.add(
                embeddings=all_embeddings,
                metadatas=all_metadatas,
                ids=all_ids
            )

            logger.info(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºæˆåŠŸ!")
            logger.info(f"   æˆåŠŸå¤„ç†: {success_count}/{total_images} å¼ å›¾ç‰‡")
            logger.info(f"   å±•å“æ•°é‡: {len(exhibits)} ä¸ª")
            logger.info(f"   å‘é‡ç»´åº¦: {len(all_embeddings[0])} ç»´")

            # æ˜¾ç¤ºå±•å“åˆ—è¡¨
            print("\nğŸ“‹ å·²å¤„ç†çš„å±•å“åˆ—è¡¨:")
            for exhibit_id in sorted(exhibits.keys()):
                print(f"   ğŸ¨ {exhibit_id}")

            return True
        else:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾å‘é‡")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¯ è‰ºæœ¯å±•å“è¯†åˆ«ç³»ç»Ÿ - ä¿®å¤ç‰ˆï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰")
    print("=" * 60)

    # æ£€æŸ¥ä¾èµ–
    try:
        import cv2
        import chromadb
        from PIL import Image
        print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ä¾èµ–ç¼ºå¤±: {e}")
        print("è¯·è¿è¡Œ: pip install opencv-python chromadb pillow numpy")
        return

    # æ•°æ®é›†è·¯å¾„
    dataset_path = r"D:\å¤§ä¸‰ä¸Šå­¦æœŸ\äººå½¢æœºå™¨äººé¡¹ç›®å®è·µ\åŸå§‹å›¾ç‰‡\åŸå§‹å›¾ç‰‡\äº§å“è®¾è®¡"

    if not os.path.exists(dataset_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return

    print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {dataset_path}")

    # æ„å»ºå‘é‡æ•°æ®åº“
    vectorizer = ExhibitVectorizer()
    vectorizer.create_collection()

    success = vectorizer.build_vector_database(dataset_path)

    if success:
        print("\nğŸ‰ æ­å–œï¼å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼")
        print("ä¸‹ä¸€æ­¥: è¿è¡Œ API æœåŠ¡æ¥æµ‹è¯•è¯†åˆ«æ•ˆæœ")
    else:
        print("\nğŸ’¥ æ„å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»¥ä¸Šé”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()